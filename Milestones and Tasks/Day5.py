# -*- coding: utf-8 -*-
"""Day5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AIxFL-e1iZ3t23IlQ-Hcs4QoLMqLV7ZQ

# Logistic Regression Model for Fake Job Detection
"""

import pandas as pd
import re, html
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('averaged_perceptron_tagger')
nltk.download('punkt_tab')

# Load dataset (preprocessed with clean_description)
df = pd.read_csv('fake_job_postings.csv')

stop_words = set(stopwords.words("english"))
lemmatizer = WordNetLemmatizer()

def clean_text(text):
    """
    Clean raw job posting text:
    - Unescape HTML
    - Lowercase
    - Remove numbers, punctuation
    - Tokenize
    - Remove stopwords
    - Lemmatize using POS tagging
    """
    if pd.isna(text):
        return ""

    text = html.unescape(str(text))
    text = text.lower()
    text = re.sub(r'http\S+|www\S+', '', text)
    text = re.sub(r'\S+@\S+', '', text)
    text = re.sub(r'[^a-z\s]', '', text)

    tokens = nltk.word_tokenize(text)
    tokens = [t for t in tokens if t not in stop_words and len(t) > 2]

    lemmatized = [lemmatizer.lemmatize(t) for t in tokens]
    return " ".join(lemmatized)

df["clean_description"] = df["description"].apply(clean_text)

# Feature extraction using TF-IDF

vectorizer = TfidfVectorizer(max_features=5000)
X = vectorizer.fit_transform(df['clean_description'])
y = df['fraudulent']

# Split data into train & test sets

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Train Logistic Regression model
model = LogisticRegression(max_iter=200)
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate performance
print("\nAccuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))

# Check example predictions

test_samples = [
    "Work from home! Limited vacancies. Apply now.",
    "We are hiring a data scientist for our Bangalore office."
]
sample_features = vectorizer.transform(test_samples)
print("\nSample Predictions:", model.predict(sample_features))

"""# Task 1"""

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import precision_score, recall_score, f1_score

# ----- BoW Feature Extraction -----
bow_vectorizer = CountVectorizer(max_features=5000)
X_bow = bow_vectorizer.fit_transform(df['clean_description'])

# Train–test split (same seed to ensure comparability)
Xb_train, Xb_test, yb_train, yb_test = train_test_split(
    X_bow, y, test_size=0.2, random_state=42, stratify=y
)

# ----- Logistic Regression on BoW -----
bow_model = LogisticRegression(max_iter=200)
bow_model.fit(Xb_train, yb_train)

# Predictions
yb_pred = bow_model.predict(Xb_test)

# Evaluation
bow_acc  = accuracy_score(yb_test, yb_pred)
bow_prec = precision_score(yb_test, yb_pred)
bow_rec  = recall_score(yb_test, yb_pred)
bow_f1   = f1_score(yb_test, yb_pred)

print("\n---- BoW (CountVectorizer) Results ----")
print(f"Accuracy : {bow_acc:.4f}")
print(f"Precision: {bow_prec:.4f}")
print(f"Recall   : {bow_rec:.4f}")
print(f"F1-score : {bow_f1:.4f}")

# Compare with TF-IDF model metrics
from sklearn.metrics import precision_score, recall_score, f1_score

tfidf_pred = model.predict(X_test)
tfidf_acc  = accuracy_score(y_test, tfidf_pred)
tfidf_prec = precision_score(y_test, tfidf_pred)
tfidf_rec  = recall_score(y_test, tfidf_pred)
tfidf_f1   = f1_score(y_test, tfidf_pred)

print("\n---- TF-IDF Results ----")
print(f"Accuracy : {tfidf_acc:.4f}")
print(f"Precision: {tfidf_prec:.4f}")
print(f"Recall   : {tfidf_rec:.4f}")
print(f"F1-score : {tfidf_f1:.4f}")

# Simple comparison
if tfidf_acc < bow_acc:
    print("\nTF-IDF performed better.")
else:
    print("\nBoW performed better.")

"""# Task 2"""

# Predict probabilities for the test set
probs = model.predict_proba(X_test)[:, 1]  # Probability of being fake

# Add predicted probabilities to a copy of the test data
df_test = df.iloc[y_test.index].copy()
df_test['predicted_proba'] = probs

# Sort and show top 5 most suspicious (highest fake probability)
top5_fake = df_test.sort_values('predicted_proba', ascending=False).head(5)
print("\nTop 5 jobs with highest fake probability:")
print(top5_fake[['title', 'clean_description', 'predicted_proba']])

"""# Task 3"""

# we are testing how the number of TF-IDF features (max_features) affects model performance
# By changing the vocabulary size (from 1,000 → 5,000 → 10,000 words)

from sklearn.feature_extraction.text import TfidfVectorizer

for max_f in [1000, 5000, 10000]:
    tfidf_vec = TfidfVectorizer(max_features=max_f)
    X_tfidf = tfidf_vec.fit_transform(df['clean_description'])

    Xtr, Xte, ytr, yte = train_test_split(X_tfidf, y, test_size=0.2, random_state=42, stratify=y)

    temp_model = LogisticRegression(max_iter=200)
    temp_model.fit(Xtr, ytr)
    ypred = temp_model.predict(Xte)

    acc = accuracy_score(yte, ypred)
    f1  = f1_score(yte, ypred)
    print(f"max_features = {max_f} -> Accuracy: {acc:.4f}, F1: {f1:.4f}")

"""Increasing max_features usually improves accuracy up to a point (≈ 5 000 – 10 000).
Too large a vocabulary can add noise and slow training.
Choose the value where accuracy plateaus."""